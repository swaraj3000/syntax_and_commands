{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c058d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5b5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31226936",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_subset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35dbf6",
   "metadata": {},
   "source": [
    "Expanding your `plotter` library to handle a variety of complex data types and visualization needs can greatly enhance its utility and flexibility. Here are several advanced features and capabilities you might consider implementing:\n",
    "\n",
    "### 1. **Time Series Support**\n",
    "   - **Time-based Grouping**: Enable grouping data by time intervals (e.g., minutes, hours, days, weeks).\n",
    "   - **Resampling and Rolling Windows**: Support for resampling time series data to a lower or higher frequency and applying rolling window calculations.\n",
    "   - **Time Series Decomposition**: Add functionality to decompose time series into trend, seasonal, and residual components.\n",
    "\n",
    "### 2. **Advanced Data Transformations**\n",
    "   - **Pivot Tables**: Support for creating pivot tables to reshape the data format, which can be very useful for creating specific types of plots.\n",
    "   - **Data Normalization and Scaling**: Provide options for scaling and normalizing data, which is crucial for some types of analysis and machine learning feature engineering.\n",
    "   - **Conditional Transformations**: Apply transformations based on conditions; for example, applying different aggregations or filters based on group characteristics.\n",
    "\n",
    "### 3. **Interactive Visualizations**\n",
    "   - **Integration with Libraries like Plotly and Bokeh**: These libraries allow for interactive plots that users can explore dynamically.\n",
    "   - **Dashboarding Capabilities**: Offer integration with dashboard frameworks like Dash or Panel to create web-based interactive visualizations.\n",
    "\n",
    "### 4. **Statistical Analysis Tools**\n",
    "   - **Regression and Trend Lines**: Automatically fit and plot regression or other analytical trend lines on scatter plots.\n",
    "   - **Error Bars**: Implement functionality to add error bars to show the variability of the data.\n",
    "   - **Histogram Binning Control**: Provide advanced controls for the number of bins, bin width, and limits when plotting histograms.\n",
    "\n",
    "### 5. **Geospatial Data Handling**\n",
    "   - **Mapping**: Add support for plotting geospatial data on maps using libraries like Geopandas and Matplotlib Basemap or Plotly.\n",
    "   - **Geospatial Transformations**: Allow transformations like projecting coordinates, calculating distances, and generating geospatial statistics.\n",
    "\n",
    "### 6. **Multidimensional Data Support**\n",
    "   - **Heatmaps and 2D Histograms**: Implement these plots for visualizing bivariate distributions.\n",
    "   - **Parallel Coordinates**: For plotting multidimensional data to observe patterns and relations across many variables.\n",
    "\n",
    "### 7. **Customizability and Aesthetics**\n",
    "   - **Theme Support**: Allow users to apply themes to plots for consistent aesthetics easily.\n",
    "   - **Text and Annotation**: Provide extensive support for adding annotations, labels, and textual explanations directly within plots.\n",
    "\n",
    "### 8. **Performance Optimizations**\n",
    "   - **Handling Large Datasets**: Optimize the library to handle very large datasets efficiently, perhaps using libraries like Dask or Vaex for out-of-core computations.\n",
    "   - **Caching Results**: Implement caching mechanisms to speed up repeated operations on the same data.\n",
    "\n",
    "### 9. **Accessibility Features**\n",
    "   - **Accessible Visuals**: Include features that improve the accessibility of visuals, such as high-contrast themes, screen-reader support, and descriptive text elements.\n",
    "\n",
    "### 10. **Integration and Exporting**\n",
    "   - **Export Capabilities**: Allow users to export plots to various formats, including vector and raster images, or even interactive web formats.\n",
    "   - **Embedding in Applications**: Ensure plots can be easily embedded in other applications or web pages.\n",
    "\n",
    "By considering these advanced functionalities, your `plotter` library could cater to a wider range of user needs, making it a more versatile and appealing tool for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e47423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        \n",
    "    def count_plot_for_col(self,\n",
    "                  col_name,\n",
    "                  palette=\"hls\",\n",
    "                  stat=\"percent\"):\n",
    "        sns.countplot(data=self.df,\n",
    "                     x=col_name,\n",
    "                     palette=palette,\n",
    "                      stat=stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf8b980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ph/nnm9q7h11bx4kbkx6gp4k2vc0000gn/T/ipykernel_5378/4185352939.py:10: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=self.df,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = Plotter(train)\n",
    "plot.count_plot_for_col(\"click\",stat=\"percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1f9f0",
   "metadata": {},
   "source": [
    "Absolutely! Beyond the foundational techniques in data manipulation and analysis using pandas, there are several advanced techniques that can help you delve deeper into data analysis, especially for complex datasets. Here are some additional advanced techniques to consider:\n",
    "\n",
    "### 1. **Categorical Data Optimization**\n",
    "\n",
    "Pandas supports categorical data types, which can significantly reduce memory usage and speed up operations on datasets with repetitive text data.\n",
    "\n",
    "```python\n",
    "# Convert a column to categorical type\n",
    "df['A'] = df['A'].astype('category')\n",
    "```\n",
    "\n",
    "### 2. **MultiIndex / Hierarchical Indexing**\n",
    "\n",
    "This feature allows you to work with higher-dimensional data using lower-dimensional data structures like DataFrame and Series.\n",
    "\n",
    "```python\n",
    "# Setting a MultiIndex\n",
    "df.set_index(['A', 'B'], inplace=True)\n",
    "\n",
    "# Slicing data with a MultiIndex\n",
    "sliced = df.loc[('foo', 'one')]\n",
    "```\n",
    "\n",
    "### 3. **Query Method**\n",
    "\n",
    "Pandas `query()` method allows for string-expressed conditional filtering, which can make querying more readable and concise.\n",
    "\n",
    "```python\n",
    "# Using query to filter data\n",
    "result = df.query('D > 1 and E < 5')\n",
    "```\n",
    "\n",
    "### 4. **Conditional Operations**\n",
    "\n",
    "Pandas `where()` and `mask()` are useful for conditional selections and replacements, which can be applied across whole DataFrames or Series.\n",
    "\n",
    "```python\n",
    "# Conditional operation with where\n",
    "df['new_column'] = df['D'].where(df['D'] > 2, other=0)\n",
    "```\n",
    "\n",
    "### 5. **Eval and Expression Evaluation**\n",
    "\n",
    "The `eval()` and `query()` functions in pandas use string expressions to efficiently compute operations using DataFrames.\n",
    "\n",
    "```python\n",
    "# Efficiently compute expressions\n",
    "df.eval('G = D + E', inplace=True)\n",
    "```\n",
    "\n",
    "### 6. **Data Transformation Using Apply and Map**\n",
    "\n",
    "These methods are extremely powerful for applying functions to data, either to entire DataFrames, individual columns, or elements.\n",
    "\n",
    "```python\n",
    "# Apply a function across a DataFrame\n",
    "df['D'] = df['D'].apply(lambda x: x ** 2)\n",
    "\n",
    "# Map can be used for substituting each value in a Series\n",
    "df['A'] = df['A'].map({'foo': 'good', 'bar': 'bad'})\n",
    "```\n",
    "\n",
    "### 7. **Memory Usage Inspection**\n",
    "\n",
    "Pandas provides tools to help you understand and optimize the memory usage of your DataFrame.\n",
    "\n",
    "```python\n",
    "# Get detailed memory usage\n",
    "df.memory_usage(deep=True)\n",
    "```\n",
    "\n",
    "### 8. **Integration with SQL**\n",
    "\n",
    "Pandas can interact with SQL databases using `read_sql` for reading and `to_sql` for writing data, leveraging SQL capabilities alongside pandas.\n",
    "\n",
    "```python\n",
    "import sqlite3\n",
    "\n",
    "# Connection to a SQLite database\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Read data from SQL\n",
    "pd.read_sql('SELECT * FROM my_table', conn)\n",
    "\n",
    "# Write data to SQL\n",
    "df.to_sql('my_table', conn, if_exists='replace')\n",
    "```\n",
    "\n",
    "### 9. **Handling Large Datasets**\n",
    "\n",
    "For very large datasets that don't fit into memory:\n",
    "- Use libraries like `Dask` which extends pandas data structures to handle large datasets.\n",
    "- Consider chunking large files using pandas `read_csv(chunksize=)` to process parts of the file.\n",
    "\n",
    "```python\n",
    "# Read large data in chunks\n",
    "chunk_iter = pd.read_csv('large_data.csv', chunksize=1000)\n",
    "for chunk in chunk_iter:\n",
    "    process(chunk)\n",
    "```\n",
    "\n",
    "### 10. **Advanced Visualization Techniques**\n",
    "\n",
    "While pandas provides basic plotting capabilities, integrating with libraries like Matplotlib, Seaborn, or Plotly can enable sophisticated visualizations directly from DataFrame objects.\n",
    "\n",
    "These techniques provide robust tools for handling complex data analysis tasks efficiently, allowing for detailed exploration and manipulation of datasets in Python.\n",
    "\n",
    "Pandas is a powerful library for data manipulation and analysis in Python, providing extensive capabilities for handling, transforming, and analyzing data. Here are some advanced analyses and their corresponding syntax in pandas, including time series analysis, window functions, and pivot tables.\n",
    "\n",
    "### 1. **Time Series Analysis**\n",
    "\n",
    "Pandas has built-in support for time series data, allowing you to perform various operations specific to time-indexed data:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Create a time series data\n",
    "index = pd.date_range('20200101', periods=100)\n",
    "data = pd.DataFrame({'value': range(100)}, index=index)\n",
    "\n",
    "# Resampling (e.g., calculating the mean monthly)\n",
    "monthly_mean = data.resample('M').mean()\n",
    "\n",
    "# Shifting (e.g., shift data by 2 days)\n",
    "shifted_data = data.shift(2)\n",
    "\n",
    "# Rolling window (e.g., rolling mean with a window of 3 days)\n",
    "rolling_mean = data.rolling(window=3).mean()\n",
    "```\n",
    "\n",
    "### 2. **Window Functions**\n",
    "\n",
    "Pandas supports window functions that are useful for running calculations over a set of rows related to the current row:\n",
    "\n",
    "```python\n",
    "# Load sample data\n",
    "df = pd.DataFrame({\n",
    "    'group': ['A', 'A', 'B', 'B', 'B'],\n",
    "    'value': [10, 20, 10, 30, 20]\n",
    "})\n",
    "\n",
    "# Calculate rolling sum within each group\n",
    "df['rolling_sum'] = df.groupby('group')['value'].rolling(2).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "# Calculate expanding sum\n",
    "df['expanding_sum'] = df.groupby('group')['value'].expanding().sum().reset_index(level=0, drop=True)\n",
    "\n",
    "# Calculate exponential moving average\n",
    "df['ema'] = df.groupby('group')['value'].transform(lambda x: x.ewm(span=2).mean())\n",
    "```\n",
    "\n",
    "### 3. **Pivot Tables**\n",
    "\n",
    "Pivot tables are a great tool in pandas for summarizing data:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create some example data\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [\"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"bar\"],\n",
    "    \"B\": [\"one\", \"one\", \"two\", \"two\", \"one\", \"one\"],\n",
    "    \"C\": [\"small\", \"large\", \"large\", \"small\", \"small\", \"large\"],\n",
    "    \"D\": [1, 2, 2, 3, 3, 4],\n",
    "    \"E\": [2, 3, 5, 7, 1, 0]\n",
    "})\n",
    "\n",
    "# Creating a pivot table\n",
    "pivot_table = df.pivot_table(values='D', index=['A', 'B'], columns=['C'], aggfunc=np.sum)\n",
    "```\n",
    "\n",
    "### 4. **Group By with Advanced Aggregations**\n",
    "\n",
    "Utilizing `groupby` along with multiple aggregations can reveal insights across different segments of data:\n",
    "\n",
    "```python\n",
    "# Group by multiple columns and perform different aggregation functions\n",
    "results = df.groupby(['A', 'B']).agg({\n",
    "    'D': ['sum', 'mean'],\n",
    "    'E': ['min', 'max']\n",
    "})\n",
    "```\n",
    "\n",
    "### 5. **Handling Missing Data**\n",
    "\n",
    "Pandas provides several methods to handle missing data, which is crucial in cleaning up data for analysis:\n",
    "\n",
    "```python\n",
    "# Fill missing values with a specified value\n",
    "df_filled = df.fillna(value=5)\n",
    "\n",
    "# Forward-fill missing values\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_dropped = df.dropna()\n",
    "```\n",
    "\n",
    "### 6. **Merging and Joining DataFrames**\n",
    "\n",
    "Combining data from multiple sources is often necessary in data analysis:\n",
    "\n",
    "```python\n",
    "# Create another DataFrame\n",
    "df2 = pd.DataFrame({\n",
    "    \"A\": [\"foo\", \"bar\", \"baz\"],\n",
    "    \"F\": [5, 10, 15]\n",
    "})\n",
    "\n",
    "# Merge df and df2\n",
    "merged_df = pd.merge(df, df2, on='A', how='inner')\n",
    "```\n",
    "\n",
    "Each of these techniques allows you to perform sophisticated data analysis and can be tailored further to meet specific requirements or data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566f15e",
   "metadata": {},
   "source": [
    "# How to pass lambda as external function\n",
    "\n",
    "Passing a lambda function or any Python function directly through a JSON configuration file or as a text-based argument poses a challenge due to JSON's limitations: it only supports data formats like strings, numbers, arrays, and objects, and doesn't support executable code directly.\n",
    "\n",
    "However, there are ways to approach this issue that maintain functionality while ensuring security and readability. Here are a few strategies:\n",
    "\n",
    "### 1. **Use Predefined Functions Mapped to Strings**\n",
    "Instead of passing functions directly, you can map string identifiers to predefined functions in your Python code. This way, you can specify which function to use in your JSON, and then your code can interpret these strings to execute the corresponding functions.\n",
    "\n",
    "**JSON Configuration:**\n",
    "```json\n",
    "{\n",
    "  \"apply_function\": \"square_root\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "import math\n",
    "\n",
    "def square_root(x):\n",
    "    return math.sqrt(x)\n",
    "\n",
    "def increment(x):\n",
    "    return x + 1\n",
    "\n",
    "functions_map = {\n",
    "    \"square_root\": square_root,\n",
    "    \"increment\": increment\n",
    "}\n",
    "\n",
    "config = {\n",
    "  \"apply_function\": \"square_root\"\n",
    "}\n",
    "\n",
    "# Using the function from the map\n",
    "df['column'] = df['column'].apply(functions_map[config['apply_function']])\n",
    "```\n",
    "\n",
    "### 2. **Custom Function Definition in Python**\n",
    "If you need custom functionality, allow users to write their functions in Python and pass the function name as part of the configuration. This requires a bit more trust and control but is flexible.\n",
    "\n",
    "**JSON Configuration:**\n",
    "```json\n",
    "{\n",
    "  \"apply_function\": \"custom_function\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "def custom_function(x):\n",
    "    # User-defined logic\n",
    "    return x * 2\n",
    "\n",
    "config = {\n",
    "  \"apply_function\": \"custom_function\"\n",
    "}\n",
    "\n",
    "# Assuming the function is defined in the same scope or is importable\n",
    "df['column'] = df['column'].apply(locals()[config['apply_function']])\n",
    "```\n",
    "\n",
    "### 3. **Using Eval Safely**\n",
    "For truly dynamic operations where the user might need to define their logic on the fly, you could use `eval()` carefully to execute code defined in a string. However, this approach poses significant security risks (executing arbitrary code) and should be used with extreme caution and restricted environments.\n",
    "\n",
    "**JSON Configuration:**\n",
    "```json\n",
    "{\n",
    "  \"apply_function\": \"x**2 if x > 0 else -x\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "config = {\n",
    "  \"apply_function\": \"x**2 if x > 0 else -x\"\n",
    "}\n",
    "\n",
    "# Dangerous! Use only in a secure, controlled way\n",
    "df['column'] = df['column'].apply(lambda x: eval(config['apply_function']))\n",
    "```\n",
    "\n",
    "### 4. **External Python Script or Module**\n",
    "A more secure and manageable way might be to allow users to specify an external Python script or module where they define their functions. The main application can then import these modules dynamically and use the functions defined therein.\n",
    "\n",
    "**JSON Configuration:**\n",
    "```json\n",
    "{\n",
    "  \"module\": \"user_defined_module\",\n",
    "  \"function\": \"user_defined_function\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "import importlib\n",
    "\n",
    "config = {\n",
    "  \"module\": \"user_defined_module\",\n",
    "  \"function\": \"user_defined_function\"\n",
    "}\n",
    "\n",
    "module = importlib.import_module(config['module'])\n",
    "function_to_apply = getattr(module, config['function'])\n",
    "\n",
    "df['column'] = df['column'].apply(function_to_apply)\n",
    "```\n",
    "\n",
    "Each of these approaches has its benefits and drawbacks, especially regarding security and flexibility. Carefully consider which method best fits your needs, balancing ease of use with safety and control over the execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913c2138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  'import pandas as pd \\nfrom matplotlib import pyplot as plt\\nimport numpy as np \\nimport seaborn as sns\\nfrom matplotlib.ticker import FuncFormatter',\n",
       "  \"pd.options.display.float_format = '{:.4f}'.format\",\n",
       "  'train = pd.read_csv(\"../data/train_subset.csv\")',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name=col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     col_name,\\n                     palette=palette,\\n                     stat=stat)',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name=col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       "  'plot = Plotter(train)\\nplot.count_plot(\"click\")',\n",
       "  'plot = Plotter(train)\\nplot.count_plot(\"click\",stat=\"proportion\")',\n",
       "  'plot = Plotter(train)\\nplot.count_plot(\"click\",stat=\"percent\")',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot_for_col(self,\\n                  col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       "  'plot = Plotter(train)\\nplot.count_plot_for_col(\"click\",stat=\"percent\")',\n",
       "  'locals()'],\n",
       " '_oh': {},\n",
       " '_dh': [PosixPath('/Users/swarajjain/Projects/back_to_basics/eda/click_through_rate_prediction/notebooks')],\n",
       " 'In': ['',\n",
       "  'import pandas as pd \\nfrom matplotlib import pyplot as plt\\nimport numpy as np \\nimport seaborn as sns\\nfrom matplotlib.ticker import FuncFormatter',\n",
       "  \"pd.options.display.float_format = '{:.4f}'.format\",\n",
       "  'train = pd.read_csv(\"../data/train_subset.csv\")',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name=col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     col_name,\\n                     palette=palette,\\n                     stat=stat)',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name=col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       "  'plot = Plotter(train)\\nplot.count_plot(\"click\")',\n",
       "  'plot = Plotter(train)\\nplot.count_plot(\"click\",stat=\"proportion\")',\n",
       "  'plot = Plotter(train)\\nplot.count_plot(\"click\",stat=\"percent\")',\n",
       "  'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot_for_col(self,\\n                  col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       "  'plot = Plotter(train)\\nplot.count_plot_for_col(\"click\",stat=\"percent\")',\n",
       "  'locals()'],\n",
       " 'Out': {},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x103d53b20>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x103dc4670>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x103dc4670>,\n",
       " '_': '',\n",
       " '__': '',\n",
       " '___': '',\n",
       " '_i': 'plot = Plotter(train)\\nplot.count_plot_for_col(\"click\",stat=\"percent\")',\n",
       " '_ii': 'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot_for_col(self,\\n                  col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       " '_iii': 'plot = Plotter(train)\\nplot.count_plot(\"click\",stat=\"percent\")',\n",
       " '_i1': 'import pandas as pd \\nfrom matplotlib import pyplot as plt\\nimport numpy as np \\nimport seaborn as sns\\nfrom matplotlib.ticker import FuncFormatter',\n",
       " 'pd': <module 'pandas' from '/Users/swarajjain/anaconda3/envs/ml/lib/python3.10/site-packages/pandas/__init__.py'>,\n",
       " 'plt': <module 'matplotlib.pyplot' from '/Users/swarajjain/anaconda3/envs/ml/lib/python3.10/site-packages/matplotlib/pyplot.py'>,\n",
       " 'np': <module 'numpy' from '/Users/swarajjain/anaconda3/envs/ml/lib/python3.10/site-packages/numpy/__init__.py'>,\n",
       " 'sns': <module 'seaborn' from '/Users/swarajjain/anaconda3/envs/ml/lib/python3.10/site-packages/seaborn/__init__.py'>,\n",
       " 'FuncFormatter': matplotlib.ticker.FuncFormatter,\n",
       " '_i2': \"pd.options.display.float_format = '{:.4f}'.format\",\n",
       " '_i3': 'train = pd.read_csv(\"../data/train_subset.csv\")',\n",
       " 'train':                                id  click                 hour    C1  \\\n",
       " 0       10000640724480837632.0000      0           2014-10-21  1005   \n",
       " 1       10000679056417042432.0000      0           2014-10-21  1005   \n",
       " 2       10001868339616595968.0000      0           2014-10-21  1005   \n",
       " 3       10003539039235338240.0000      0           2014-10-21  1005   \n",
       " 4       10004510652136495104.0000      0           2014-10-21  1005   \n",
       " ...                           ...    ...                  ...   ...   \n",
       " 9999995  9998265546800240640.0000      0  2014-10-30 23:00:00  1005   \n",
       " 9999996  9998487258543216640.0000      1  2014-10-30 23:00:00  1005   \n",
       " 9999997  9998654904628432896.0000      0  2014-10-30 23:00:00  1005   \n",
       " 9999998  9998752756639795200.0000      1  2014-10-30 23:00:00  1005   \n",
       " 9999999  9999746639881207808.0000      0  2014-10-30 23:00:00  1005   \n",
       " \n",
       "          banner_pos   site_id site_domain site_category    app_id app_domain  \\\n",
       " 0                 0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
       " 1                 1  fe8cc448    9166c161      0569f928  ecad2386   7801e8d9   \n",
       " 2                 1  e151e245    7e091613      f028772b  ecad2386   7801e8d9   \n",
       " 3                 0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
       " 4                 0  543a539e    c7ca3108      3e814130  ecad2386   7801e8d9   \n",
       " ...             ...       ...         ...           ...       ...        ...   \n",
       " 9999995           0  85f751fd    c4e18dd6      50e219e0  f0d41ff1   2347f47a   \n",
       " 9999996           0  83a0ad1a    5c9ae867      f028772b  ecad2386   7801e8d9   \n",
       " 9999997           0  85f751fd    c4e18dd6      50e219e0  396df801   2347f47a   \n",
       " 9999998           1  e151e245    7e091613      f028772b  ecad2386   7801e8d9   \n",
       " 9999999           0  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9   \n",
       " \n",
       "          ... device_type device_conn_type    C14  C15  C16   C17  C18  C19  \\\n",
       " 0        ...           1                0  15706  320   50  1722    0   35   \n",
       " 1        ...           1                0  18993  320   50  2161    0   35   \n",
       " 2        ...           1                0  17747  320   50  1974    2   39   \n",
       " 3        ...           1                0  15699  320   50  1722    0   35   \n",
       " 4        ...           1                0  20352  320   50  2333    0   39   \n",
       " ...      ...         ...              ...    ...  ...  ...   ...  ...  ...   \n",
       " 9999995  ...           1                0  22592  320   50  2603    3  171   \n",
       " 9999996  ...           1                0  19772  320   50  2227    0  935   \n",
       " 9999997  ...           1                0  23866  320   50  2736    0   33   \n",
       " 9999998  ...           1                0  17262  320   50  1872    3   39   \n",
       " 9999999  ...           1                0  22257  320   50  2545    0  431   \n",
       " \n",
       "             C20  C21  \n",
       " 0        100084   79  \n",
       " 1            -1  157  \n",
       " 2        100019   33  \n",
       " 3        100084   79  \n",
       " 4            -1  157  \n",
       " ...         ...  ...  \n",
       " 9999995  100161   61  \n",
       " 9999996      -1   48  \n",
       " 9999997      -1  246  \n",
       " 9999998  100173   23  \n",
       " 9999999  100084  221  \n",
       " \n",
       " [10000000 rows x 24 columns],\n",
       " '_i4': 'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name=col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     col_name,\\n                     palette=palette,\\n                     stat=stat)',\n",
       " '_i5': 'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name=col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       " '_i6': 'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot(self,\\n                  col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       " 'Plotter': __main__.Plotter,\n",
       " '_i7': 'plot = Plotter(train)\\nplot.count_plot(\"click\")',\n",
       " 'plot': <__main__.Plotter at 0x3bee458a0>,\n",
       " '_i8': 'plot = Plotter(train)\\nplot.count_plot(\"click\",stat=\"proportion\")',\n",
       " '_i9': 'plot = Plotter(train)\\nplot.count_plot(\"click\",stat=\"percent\")',\n",
       " '_i10': 'class Plotter:\\n    \\n    def __init__(self,df):\\n        self.df = df\\n        \\n    def count_plot_for_col(self,\\n                  col_name,\\n                  palette=\"hls\",\\n                  stat=\"percent\"):\\n        sns.countplot(data=self.df,\\n                     x=col_name,\\n                     palette=palette,\\n                      stat=stat)',\n",
       " '_i11': 'plot = Plotter(train)\\nplot.count_plot_for_col(\"click\",stat=\"percent\")',\n",
       " '_i12': 'locals()'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57a40f",
   "metadata": {},
   "source": [
    "## Eval Expression \n",
    "The `eval()` function in pandas is powerful for evaluating expressions involving DataFrame columns, but it does not directly support group-by operations. The primary use of `eval()` is for element-wise operations, column transformations, and filtering, rather than for grouped or aggregate computations.\n",
    "\n",
    "### Understanding `eval()` and `groupby`\n",
    "\n",
    "1. **`eval()`**:\n",
    "   - Designed for efficient computation of expressions involving DataFrame columns.\n",
    "   - Can handle simple arithmetic, logical operations, and access to DataFrame columns, but it is not intended for operations that involve grouping data.\n",
    "\n",
    "2. **`groupby()`**:\n",
    "   - Used for splitting data into groups based on some criteria, applying a function to each group independently, and combining the results.\n",
    "   - Supports complex manipulations and aggregations of grouped data which are not possible through `eval()`.\n",
    "\n",
    "### Alternative: Using `groupby()` with `agg()` or `apply()`\n",
    "\n",
    "To perform operations that involve grouping, you would typically use the `groupby()` method along with `agg()`, `apply()`, or `transform()`. Here’s how you can use these methods for group-based calculations:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Data': [10, 15, 10, 20, 30, 40],\n",
    "    'Values': [100, 150, 200, 250, 300, 350]\n",
    "})\n",
    "\n",
    "# Using groupby with agg to perform aggregation\n",
    "result = df.groupby('Category').agg({\n",
    "    'Data': 'sum',  # Summing up the Data column'\n",
    "```\n",
    "\n",
    "No, you cannot use the `groupby()` function directly within a `pandas.eval()` expression. The `eval()` function is designed for element-wise operations and is limited to operations that can be expressed as array expressions. It does not support operations that inherently involve a change in the dimensions or structure of the DataFrame, such as grouping.\n",
    "\n",
    "### What `eval()` Can Do\n",
    "`eval()` is most useful for operations such as:\n",
    "- Arithmetic operations (`+, -, *, /`)\n",
    "- Comparison operations (`>, <, >=, <=, ==, !=`)\n",
    "- Logical operations (`and, or, not`)\n",
    "- Accessing DataFrame columns for calculations\n",
    "\n",
    "### Correct Way to Use `groupby`\n",
    "To perform operations that involve grouping, you should use the `groupby()` method on the DataFrame itself. After grouping, you can apply aggregation functions, transformations, or filter operations using `agg()`, `apply()`, or `filter()` respectively.\n",
    "\n",
    "Here's a quick example of how to correctly use `groupby()`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Data': [10, 15, 10, 20, 30, 40],\n",
    "    'Values': [100, 150, 200, 250, 300, 350]\n",
    "})\n",
    "\n",
    "# Using groupby to aggregate data\n",
    "aggregated_data = df.groupby('Category').agg({\n",
    "    'Data': 'sum',  # Summing up the 'Data' for each category\n",
    "    'Values': 'mean'  # Calculating the mean of 'Values' for each category\n",
    "})\n",
    "\n",
    "print(aggregated_data)\n",
    "```\n",
    "\n",
    "### If You Need Dynamic Expression Evaluation with Grouping\n",
    "If your use case involves dynamically constructing expressions for grouped data (something similar to what `eval()` facilitates but with `groupby`), you might need to manually parse these expressions and apply them using `apply()` or `agg()` with `groupby()`. This is not straightforward and lacks the simplicity and security guarantees of `eval()`.\n",
    "\n",
    "For example, to dynamically apply a function based on user input in a safe way without `eval()`, you can use a dictionary to map user inputs to secure function calls or use `pd.eval()` with safe arguments within an `apply()` call after a `groupby()`:\n",
    "\n",
    "```python\n",
    "# Example of dynamically choosing an operation\n",
    "operations = {\n",
    "    'sum_data': lambda x: x['Data'].sum(),\n",
    "    'mean_values': lambda x: x['Values'].mean()\n",
    "}\n",
    "\n",
    "# User input specifies operation\n",
    "user_input = 'sum_data'\n",
    "\n",
    "# Apply user-selected operation in a groupby context\n",
    "result = df.groupby('Category').apply(operations[user_input])\n",
    "print(result)\n",
    "```\n",
    "\n",
    "This approach keeps the flexibility of applying dynamic operations while avoiding the direct evaluation of potentially unsafe strings as code.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea38589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFProcessor:\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __rename_cols(self,col_dic):\n",
    "        for key,val in col_dic:\n",
    "            self.df.rename(columns=col_dic)\n",
    "    \n",
    "    def __reset_index(self,inplace=True):\n",
    "        self.df.reset_index(inplace=inplace)\n",
    "    \n",
    "    def data_transformation_on_each_element_in_col(self,func_name,new_col_name=new_col_name,col_name=col_name):\n",
    "        self.df[new_col_name] = self.df[col_name].apply(locals()[func_name])\n",
    "        \n",
    "    def substituting_each_element_in_col(self,new_col_name,col_name,dic):\n",
    "        self.df[new_col_name] = self.df[col_name].map(dic)\n",
    "    \n",
    "    def filtering_cols(self,eval_expression,inplace=False):\n",
    "        return self.df.eval(eval_expression,inplace=inplace)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "508px",
    "left": "1280.64px",
    "top": "535px",
    "width": "288px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
